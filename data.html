<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<<<<<<< HEAD
    <title>Welcome to NUDT's kyliner Home</title>
=======
    <title>Welcome to Text Mining Group</title>
>>>>>>> 3
    <link rel="stylesheet" href="css/com.css">
    <link rel="stylesheet" href="css/data.css">

</head>
<body>

<div id="home_img"><img src="image/nlp.jpg"></div>

<div id="nav">
    <div id="nav1" >
        <a href="index.html"><div class="topnav center" >home</div></a>
        <a href="people.html"><div class="topnav center">people</div></a>
<<<<<<< HEAD
        <a href="publication.html"><div class="topnav center" id="spnav">publication</div></a>
=======
        <a href="publication.html"><div class="topnav center" id="spnav">Recent</div></a>
>>>>>>> 3
        <a href="demo.html"><div class="topnav center">demo</div></a>
        <a href="data.html"><div class="topnav center"><span class="fontcolorred">data</span></div></a>
    </div>
</div>
<!--底栏-->

<div class="data_download">
    <h1 class="center">Datesets Download</h1>
    <div class="Text">
        <h2>&#10040 Text classification</h2>
        <div class="dataset_detail">
            &#9658<a href="http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html?spm=a2c4e.11153959.blogcont221671.12.4de51081Bwa0v4">Reuters-21578 Text Categorization Collection </a>(Reuters21578)
        <p class="detail">This is a collection of documents that appeared on Reuters newswire in 1987. The documents were assembled and indexed with categories. </p>
        </div>
        <div class="dataset_detail">
            &#9658<a href="http://ai.stanford.edu/~amaas/data/sentiment/?spm=a2c4e.11153959.blogcont221671.14.4de51081Kpxf8f">Large Movie Review Dataset</a>(Stamford)
            <p class="detail">This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. </p>
        </div>
        <div class="dataset_detail">
            &#9658<a href="http://www.cs.cornell.edu/people/pabo/movie-review-data/?spm=a2c4e.11153959.blogcont221671.15.4de510813qU1Tc">Movie Review Data</a>(cornell)
            <p class="detail">This is movie-review data for use in sentiment-analysis experiments. </p>
        </div>
    </div>

    <div class="Text">
        <h2>&#10040 The image captions</h2>
        <div class="dataset_detail">
            &#9658<a href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html?spm=a2c4e.11153959.blogcont221671.21.4de51081DQGtbT">Flickr 8K </a>
            <p class="detail">The image captions are released under a CreativeCommons Attribution-ShareAlike license. </p>
        </div>
        <div class="dataset_detail">
            &#9658<a href="http://shannon.cs.illinois.edu/DenotationGraph/?spm=a2c4e.11153959.blogcont221671.22.4de51081qi850Q">Flickr 30K</a>
            <p class="detail">This is an image caption corpus consisting of 158,915 crowd-sourced captions describing 31,783 images.  </p>
        </div>
    </div>

    <div class="Text">
        <h2>&#10040 Machine translation</h2>
        <div class="dataset_detail ">
            &#9658<a href="https://www.isi.edu/natural-language/download/hansard/?spm=a2c4e.11153959.blogcont221671.24.4de51081ulRhLb">Aligned Hansards of the 36th Parliament of Canada Release 2001-1a</a>
            <p class="detail">This release contains 1.3 million pairs of aligned text chunks (sentences or smaller fragments) from the official records (Hansards) of the 36th Canadian Parliament.</p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="http://www.statmt.org/europarl/?spm=a2c4e.11153959.blogcont221671.25.4de510819I7nSG">European Parliament Proceedings Parallel Corpus 1996-2011</a>
            <p class="detail">The Europarl parallel corpus is extracted from the proceedings of the European Parliament. It includes versions in 21 European languages.  </p>
        </div>
    </div>

    <div class="Text">
        <h2>&#10040 Question Answering Dataset</h2>
        <div class="dataset_detail ">
            &#9658<a href="https://rajpurkar.github.io/SQuAD-explorer/?spm=a2c4e.11153959.blogcont221671.27.4de510818aLEcX">The Stanford Question Answering Dataset</a>
            <p class="detail">Stanford Question Answering Dataset (SQuAD) is a new reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage. </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="https://github.com/deepmind/rc-data?spm=a2c4e.11153959.blogcont221671.28.4de51081xmf5Hr">DeepMind Question Answering Corpus</a>
            <p class="detail">This repository contains a script to generate question/answer pairs using CNN and Daily Mail articles downloaded from the Wayback Machine. </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="http://jmcauley.ucsd.edu/data/amazon/qa/?spm=a2c4e.11153959.blogcont221671.29.4de51081KeK2ep">Amazon question/answer data</a>
            <p class="detail">This dataset contains Question and Answer data from Amazon, totaling around 1.4 million answered questions. </p>
        </div>
    </div>

    <div class="Text">
        <h2>&#10040 Speech Corpus</h2>
        <div class="dataset_detail ">
            &#9658<a href="https://catalog.ldc.upenn.edu/LDC93S1?spm=a2c4e.11153959.blogcont221671.31.4de51081SfWiwN">TIMIT Acoustic-Phonetic Continuous Speech Corpus</a>
            <p class="detail">TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences.  </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="http://voxforge.org/?spm=a2c4e.11153959.blogcont221671.32.4de51081Rklra6">VoxForge</a>
            <p class="detail">VoxForge was set up to collect transcribed speech for use with Free and  Open Source Speech Recognition Engines (on Linux, Windows and Mac).  </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="http://www.openslr.org/12/?spm=a2c4e.11153959.blogcont221671.33.4de51081RmrYsJ">LibriSpeech ASR corpus</a>
            <p class="detail">LibriSpeech is a corpus of approximately 1000 hours of 16kHz read English speech, prepared by Vassil Panayotov with the assistance of Daniel Povey. </p>
        </div>
    </div>

    <div class="Text">
        <h2>&#10040 Textual Corpus </h2>
        <div class="dataset_detail ">
            &#9658<a href="https://archive.ics.uci.edu/ml/datasets/Legal+Case+Reports?spm=a2c4e.11153959.blogcont221671.35.4de51081XFTp62">Legal Case Reports Data Set</a>
            <p class="detail">This dataset contains Australian legal cases from the Federal Court of Australia (FCA). The cases were downloaded from AustLII ([Web Link]) included all cases from the year 2006,2007,2008 and 2009.   </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="http://www-nlpir.nist.gov/related_projects/tipster_summac/cmp_lg.html?spm=a2c4e.11153959.blogcont221671.36.4de51081QUIPTG">TIPSTER Text Summarization Evaluation Conference</a>(SUMMAC)
            <p class="detail">The corpus was prepared by The MITRE Corporation and the University of Edinburgh.  </p>
        </div>
        <div class="dataset_detail ">
            &#9658<a href="https://catalog.ldc.upenn.edu/LDC2002T31?spm=a2c4e.11153959.blogcont221671.37.4de51081H06S5l">The AQUAINT Corpus of English News Text</a>
            <p class="detail">The data files contain roughly 375 million words correlating to about 3GB of data. </p>
        </div>
    </div>


</div>

<div id="foot">
<<<<<<< HEAD
    <p class="center">&copy;2018 NUDT's kyliner Home</p>
=======
    <p class="center">&copy;2018 TMG@NUDT</p>
>>>>>>> 3
</div>
</body>
</html>